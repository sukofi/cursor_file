# それは宝くじではなく競争である：勾配降下法がネットワークの容量をタスクに適応させる仕組みの理解

## 原題
It's not a Lottery, it's a Race: Understanding How Gradient Descent Adapts the Network's Capacity to the Task

## アブストラクト
ニューラルネットワークの理論的理解は、その実証的成功に遅れをとっています。重要な未解明の現象の一つは、勾配降下法による訓練過程で、理論上のネットワーク容量がどのようにしてタスクに適合する有効容量へと縮小されるのかという点です。本研究では、単一隠れ層のReLUネットワークにおける個々のニューロンレベルでの学習ダイナミクスを分析し、勾配降下法がこの過程を達成するメカニズムを調査します。相互整列、アンロック、レースという三つの動的原理を特定し、これらが等価なニューロンの統合や低ノルム重みの剪定を通じて訓練後に容量を効果的に削減できる理由を説明します。特に、ロッテリー・チケット仮説の背後にあるメカニズム、すなわち一部のニューロンの特定の有益な初期条件がなぜ高い重みノルムを獲得するのかを明らかにします。

## 文献情報
- **arXiv ID**: 2602.04832v1
- **公開日**: 2026-02-04
- **PDF**: [arXiv PDF](https://arxiv.org/pdf/2602.04832v1.pdf)

## タグ
#ニューラルネットワーク #勾配降下法 #容量適応 #ロッテリー・チケット仮説 #学習ダイナミクス

---
*自動取得日: 2026-02-05*
*テーマ: 人工知能*
