# マルチレイヤー・クロスアテンションはマルチモーダル・インコンテキスト学習において理論的に最適である

#マルチモーダル学習, #インコンテキスト学習, #クロスアテンション, #トランスフォーマー, #ベイズ最適性

## 概要
近年の進展により、現代のアテンションベースのニューラルネットワークにおけるインコンテキスト学習のメカニズム理解が急速に深まっている。しかし、既存の研究は単一モーダルデータに限定されており、マルチモーダルデータに対するインコンテキスト学習の理論的基盤は十分に解明されていない。本論文では、マルチモーダル学習を研究するための数理的に扱いやすいフレームワークを導入し、トランスフォーマーに類似したアーキテクチャがいつベイズ最適性能を文脈内で回復できるかを探る。マルチモーダル問題をモデル化するために、観測データが潜在因子モデルに基づくと仮定する。第一の結果として表現力に関する否定的な見解を示し、単層の線形セルフアテンションではタスク分布全体にわたりベイズ最適予測器を回復できないことを証明した。この制約を克服するために、新たな線形化されたクロスアテンション機構を導入し、クロスアテンション層数と文脈長が共に大きい領域で研究を行う。このクロスアテンション機構は勾配流によって最適化されると理論的にベイズ最適であることを示した。本研究は、インコンテキスト学習における深層性の利点を強調し、マルチモーダル分布に対するクロスアテンションの有用性を理論的に証明したものである。
