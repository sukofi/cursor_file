# 視覚知覚から深層共感へ：マルチモーダルLLMとマルチエージェント協働による家-木-人描画の自動評価フレームワーク

## 元情報
- **タイトル**: From Visual Perception to Deep Empathy: An Automated Assessment Framework for House-Tree-Person Drawings Using Multimodal LLMs and Multi-Agent Collaboration
- **リンク**: [http://arxiv.org/abs/2512.21360v1](http://arxiv.org/abs/2512.21360v1)
- **PDF**: [http://arxiv.org/pdf/2512.21360v1](http://arxiv.org/pdf/2512.21360v1)

## 要約
背景：1948年にジョン・バックが提唱した家-木-人（HTP）描画テストは、臨床心理学で広く用いられている投影法の一つです。しかし、採点基準のばらつきや評価者の主観に依存している点、統一された定量的コーディングシステムの欠如といった課題が長らく存在してきました。  
結果：定量実験では、マルチモーダル大規模言語モデル（MLLM）の解釈と人間専門家の解釈との平均意味的類似度は約0.75（標準偏差約0.05）でした。構造的に専門家向けに整備されたデータセットでは、この類似度が0.85に上昇し、専門家レベルの理解度を示しました。質的分析では、社会心理学的視点とスティグマ除去の物語を統合したマルチエージェントシステムが、視覚的幻覚の誤りを効果的に修正し、高い生態学的妥当性と内的一貫性を備えた心理報告を生み出しました。  
結論：これらの結果は、マルチモーダル大規模モデルが投影法評価における標準化ツールとしての可能性を示しています。提案されたマルチエージェントフレームワークは役割分担により特徴認識と心理推論を分離し、デジタルメンタルヘルスサービスの新たなパラダイムを提供します。

## タグ
#投影法 #心理評価 #マルチモーダルAI #マルチエージェント #メンタルヘルスAI
