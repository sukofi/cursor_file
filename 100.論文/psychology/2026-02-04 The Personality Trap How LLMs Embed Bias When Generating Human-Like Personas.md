# The Personality Trap: How LLMs Embed Bias When Generating Human-Like Personas

## 概要 (Abstract)
本論文では、性格質問票の回答から合成人口を生成する際の大規模言語モデル（LLM）のバイアスを検討する。5種類のLLMを用いて、まず生成されたペルソナの社会人口学的属性の代表性および潜在的バイアス、ならびに意図された性格特性との整合性を評価した。LLMは性格と社会人口学的変数の既知の相関関係を再現することに成功した一方で、すべてのモデルにおいて、若く、教育を受けた白人の異性愛者で、西洋出身の中道もしくは進歩的な政治的見解および世俗的またはキリスト教的信念を持つWEIRD（西洋、教育、工業、富裕、民主的）なバイアスが顕著に現れた。第二の分析では、入力特性を操作して神経症傾向と精神病傾向のスコアを最大化した。特に精神病傾向を最大化した場合、いくつかのモデルがノンバイナリーおよびLGBTQ+のアイデンティティを過剰に生成し、ステレオタイプ化や社会的に疎外された集団の病理化の懸念を示した。本研究の結果は、心理学的に基盤をもつ合成人口生成におけるLLMの可能性とリスクの双方を浮き彫りにしている。

## 元のアブストラクト (Original Abstract)
This paper examines biases in large language models (LLMs) when generating synthetic populations from responses to personality questionnaires. Using five LLMs, we first assess the representativeness and potential biases in the sociodemographic attributes of the generated personas, as well as their alignment with the intended personality traits. While LLMs successfully reproduce known correlations between personality and sociodemographic variables, all models exhibit pronounced WEIRD (western, educated, industrialized, rich and democratic) biases, favoring young, educated, white, heterosexual, Western individuals with centrist or progressive political views and secular or Christian beliefs. In a second analysis, we manipulate input traits to maximize Neuroticism and Psychoticism scores. Notably, when Psychoticism is maximized, several models produce an overrepresentation of non-binary and LGBTQ+ identities, raising concerns about stereotyping and the potential pathologization of marginalized groups. Our findings highlight both the potential and the risks of using LLMs to generate psychologically grounded synthetic populations.

## 引用元 / リンク
- **arXiv URL**: [http://arxiv.org/abs/2602.03334v1](http://arxiv.org/abs/2602.03334v1)
- **PDF URL**: [https://arxiv.org/pdf/2602.03334v1](https://arxiv.org/pdf/2602.03334v1)

---
取得日: 2026-02-04
